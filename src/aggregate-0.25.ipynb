{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96620f-8743-47d3-8ac6-d0e03dee1980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle, os, io, time\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import xagg as xa\n",
    "import re\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import itertools\n",
    "\n",
    "# read in the ADM1-levle shapefile - NOTE: the augmented shapefile is created in src/prepare_weights_and_shapefiles.R and includes ADM0 territories w/o ADM1 sub-regions\n",
    "ds_gdf = gpd.read_file(\"../../sharepoint/Data/GADM/gadm36_levels_simple_augmented/adm1_augmented.shp\")\n",
    "\n",
    "# define an aggregation function\n",
    "def aggregate(inpath, outpath, weightmap=None, gdf_regions=None):\n",
    "    if os.path.exists(outpath):\n",
    "        print('No aggregation carried out as ' + outpath + 'already exists')\n",
    "        return None\n",
    "    \n",
    "    if weightmap is None:\n",
    "        if gdf_regions is None:\n",
    "            gdf_regions = gpd.read_file(\"../../sharepoint/Data/GADM/gadm36_levels_simple_augmented/adm1_augmented.shp\")\n",
    "        \n",
    "        ds_imp = xr.open_dataset(inpath)\n",
    "        weightmap = xa.pixel_overlaps(ds_imp, gdf_regions, subset_bbox=False)\n",
    "                \n",
    "    try:\n",
    "        ds_imp = xr.open_dataset(inpath)\n",
    "        aggregated = xa.aggregate(ds_imp, weightmap)\n",
    "        aggregated.to_netcdf(outpath)\n",
    "    except Exception as ex:\n",
    "        print(f\"Could not convert {filepath}.\")\n",
    "        print(ex)\n",
    "        \n",
    "    # Test it!\n",
    "    ds_test = xr.open_dataset(outpath)\n",
    "    if np.max(getattr(ds_test, list(ds_test.keys())[-1])) > 1e100:\n",
    "        print(\"Failed check.\")\n",
    "        exit() # Check this\n",
    "        os.unlink(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56836e2f-b759-4d51-bfa4-3315162b5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the weightmap - COMMENTED OUT TO AVOID EXPENSIVE RE-RUNS\n",
    "#ds_example = xr.open_dataset('/net/argon/landclim/fbatibeniz/clim_indices/data/cmip6-ng/pr/ann_totd_regrid/ann_totd_regrid_pr_UKESM1-0-LL_ssp370_r1i1p1f2_g025.nc')\n",
    "#weightmap_era5_to_adm1 = xa.pixel_overlaps(ds_example, ds_gdf, subset_bbox=False)\n",
    "#print(\"weightmap calculated!\")\n",
    "## for saving out\n",
    "#file_weightmap = open('../../sharepoint/Data/GADM/gadm36_levels_simple_augmented/weightmap_era5_to_adm1.p', 'wb') \n",
    "#pickle.dump(weightmap_era5_to_adm1, file_weightmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de7998-e722-4b2e-8201-d63afdfa39e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for loading\n",
    "file_weightmap = '../../sharepoint/Data/GADM/gadm36_levels_simple_augmented/weightmap_era5_to_adm1.p'\n",
    "weightmap_era5_to_adm1 = pickle.load(open(file_weightmap, 'rb'))\n",
    "weightmap_era5_to_adm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ad057-ed4b-4f61-973a-3eea3848234a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to find all file names for a specific climate variable\n",
    "def get_filepaths_per_variable(varname, indir='/net/argon/landclim/fbatibeniz/clim_indices/data/cmip6-ng'):\n",
    "    # define the variable prefix (pr for precip, tas for temperature) - this is needed to reproduce Fulden's directory system\n",
    "    if bool(re.search(r'ann_mean_regrid|dtd_var_regrid|bc_ann_mean_regrid|bc_dtd_var_regrid', varname)):\n",
    "        varname_prefix = 'tas'\n",
    "    elif bool(re.search(r'ann_totd_regrid|btstrp_pr999_regrid|mon_totd_regrid|wet_days_regrid|bc_ann_totd_regrid|bc_btstrp_pr999_regrid|bc_mon_totd_regrid|bc_wet_days_regrid', varname)):\n",
    "        varname_prefix = 'pr'\n",
    "    else:\n",
    "        raise ValueError('varname did not match any of the reg ex fo climate index variable names')\n",
    "\n",
    "    # read in all filenames and throw an error if target folder is empty\n",
    "    indir_varspecific = indir + '/' + varname_prefix + '/' + varname\n",
    "    filenames = os.listdir(indir_varspecific)\n",
    "    if len(filenames) == 0:\n",
    "        raise Exception('The directory ' + indir_varspecific + 'is empty. Please inspect')\n",
    "        \n",
    "    # subset to netCDF files based on the \".nc\" ending to avoid matching temporary files etc.\n",
    "    nc_files = [filename for filename in filenames if filename.endswith(\".nc\")]\n",
    "\n",
    "    return([indir_varspecific + '/' + x for x in nc_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75ecbc-0ef2-4359-bb69-f82c003c857b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# peak at the files - COMMENTED OUT, ONLY FOR MANUAL INSPECTION\n",
    "# print(os.listdir('/net/argon/landclim/fbatibeniz/clim_indices/data/cmip6-ng/pr'))\n",
    "# get_filepaths_per_variable(\"mon_totd_regrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a9149-3ada-43be-8cbd-47aebb0a62cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write a wrapper around aggregate to facilitate parallel processing\n",
    "def aggregate_parallel(inpath, outdir='../../sharepoint/Data/Climate projections/cmip6_ng_adm1_new', weightmap=None, gdf_regions=None):\n",
    "    # extract the variable name based on a regex\n",
    "    varname = re.findall('(?<=\\\\/pr\\\\/|tas\\\\/).+(?=\\\\/)', inpath)[0]\n",
    "    filename = re.findall('(?<=' + varname + '\\\\/).+$', inpath)[0]\n",
    "    \n",
    "    # create a folder named to the value of varname under the outdir directory unless it already exists\n",
    "    try:\n",
    "        os.mkdir(outdir + '/' + varname)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # aggregate\n",
    "    aggregate(inpath, outdir + '/' + varname + '/' + filename, weightmap, gdf_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a314422-9b4c-4311-a469-3a7f06e05914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the aggregate_parallel() function in parallel on all filenames - NOTE: warnings by the xagg package about NaN values in the time dimension are limited to the CAMS model which features NA values in 2100 only\n",
    "# NOTE: using parallel processing for monthly precip totals maxes out the memory, hence we omit this indicator here and use a for-loop below\n",
    "pool = Pool()\n",
    "files_bc = [*get_filepaths_per_variable('bc_ann_mean_regrid'),\n",
    "            *get_filepaths_per_variable('bc_dtd_var_regrid'),\n",
    "            *get_filepaths_per_variable('bc_ann_totd_regrid'),\n",
    "            #*get_filepaths_per_variable('bc_mon_totd_regrid'),\n",
    "            *get_filepaths_per_variable('bc_wet_days_regrid'),\n",
    "            *get_filepaths_per_variable('bc_btstrp_pr999_regrid')]\n",
    "pool.starmap(aggregate_parallel, zip(files_bc, itertools.repeat('../../sharepoint/Data/Climate projections/cmip6_ng_adm1_new'), itertools.repeat(weightmap_era5_to_adm1)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193e2c2-6405-4d97-86d4-91d7b31ed4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# repeat for raw CMIP6 data w/o bias correction - NOTE: warnings by the xagg package about NaN values in the time dimension are limited to the CAMS model which features NA values in 2100 only\n",
    "# NOTE: using parallel processing for monthly precip totals maxes out the memory, hence we omit this indicator here and use a for-loop below\n",
    "pool = Pool()\n",
    "files_original = [*get_filepaths_per_variable('ann_mean_regrid'),\n",
    "            *get_filepaths_per_variable('dtd_var_regrid'),\n",
    "            *get_filepaths_per_variable('ann_totd_regrid'),\n",
    "            #*get_filepaths_per_variable('mon_totd_regrid'),\n",
    "            *get_filepaths_per_variable('wet_days_regrid'),\n",
    "            *get_filepaths_per_variable('btstrp_pr999_regrid')]\n",
    "\n",
    "pool.starmap(aggregate_parallel, zip(files_original, itertools.repeat('../../sharepoint/Data/Climate projections/cmip6_ng_adm1_new'), itertools.repeat(weightmap_era5_to_adm1)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc772529-feab-456f-aa9e-b63308050d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run a for loop for monthly totals (raw CMIP6)\n",
    "for file_jj in [*get_filepaths_per_variable('mon_totd_regrid')]:\n",
    "    print(file_jj)\n",
    "    aggregate_parallel(file_jj, outdir='../../sharepoint/Data/Climate projections/cmip6_ng_adm1_new', weightmap = weightmap_era5_to_adm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a303c09-b52a-4776-bcfc-a9a1d4097cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run a for loop for bias-corrected monthly totals\n",
    "for file_jj in [*get_filepaths_per_variable('bc_mon_totd_regrid')]:\n",
    "    print(file_jj)\n",
    "    aggregate_parallel(file_jj, outdir='../../sharepoint/Data/Climate projections/cmip6_ng_adm1_new', weightmap = weightmap_era5_to_adm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf38a8-e599-45be-9562-15a102d3aa28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-run w/o parallel processing to ensure that all files were captured (will skip files that already exist, so runtime is minimal unless some files were missed in the previous steps)\n",
    "for file_jj in [*get_filepaths_per_variable('ann_mean_regrid'),\n",
    "            *get_filepaths_per_variable('dtd_var_regrid'),\n",
    "            *get_filepaths_per_variable('ann_totd_regrid'),\n",
    "            *get_filepaths_per_variable('mon_totd_regrid'),\n",
    "            *get_filepaths_per_variable('wet_days_regrid'),\n",
    "            *get_filepaths_per_variable('btstrp_pr999_regrid'),\n",
    "            *get_filepaths_per_variable('bc_ann_mean_regrid'),\n",
    "            *get_filepaths_per_variable('bc_dtd_var_regrid'),\n",
    "            *get_filepaths_per_variable('bc_ann_totd_regrid'),\n",
    "            *get_filepaths_per_variable('bc_mon_totd_regrid'),\n",
    "            *get_filepaths_per_variable('bc_wet_days_regrid'),\n",
    "            *get_filepaths_per_variable('bc_btstrp_pr999_regrid')]:\n",
    "    print(file_jj)\n",
    "    aggregate_parallel(file_jj, outdir='../../sharepoint/Data/Climate projections/cmip6_ng_adm1_new', weightmap = weightmap_era5_to_adm1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iacpy3_2022)",
   "language": "python",
   "name": "iacpy3_2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
